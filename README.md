# Hospital_Incident_Streaming_App


## Table of Contents

- ğŸ“ [Introduction](#introduction)
- ğŸš€ [Principales CaractÃ©ristiques](#principales-caractÃ©ristiques)
- ğŸ›ï¸ [Architecture](#architecture)
- ğŸ“‹ [Cas d'Utilisation](#cas-dutilisation)
- ğŸ¥ [Hospital Incidents Streaming App](#hospital-incidents-streaming-app)
- ğŸ“ˆ [RÃ©sultats](#rÃ©sultats)
- ğŸ [Conclusion](#conclusion)

## ğŸ“Introduction

Spark Streaming est un module de traitement des donnÃ©es en temps rÃ©el dans le framework Apache Spark. Il permet aux dÃ©veloppeurs de crÃ©er des applications de traitement des donnÃ©es en continu, en ingÃ©rant et en traitant les flux de donnÃ©es en temps rÃ©el avec une latence minimale. Cette technologie est largement utilisÃ©e dans divers domaines tels que l'analyse en temps rÃ©el, la dÃ©tection d'anomalies, la surveillance, etc.

## ğŸš€Principales CaractÃ©ristiques

1. **ExtensibilitÃ©:**
   - Spark Streaming s'intÃ¨gre parfaitement avec le framework Spark, permettant une Ã©volutivitÃ© horizontale. Il exploite la mÃªme architecture RDD (Resilient Distributed Datasets) pour garantir une tolÃ©rance aux pannes et une distribution des donnÃ©es.

2. **Sources de DonnÃ©es Prises en Charge:**
   - Spark Streaming peut ingÃ©rer des donnÃ©es Ã  partir de diverses sources telles que Kafka, Flume, HDFS, Twitter, et bien d'autres. Cela offre une flexibilitÃ© considÃ©rable pour les dÃ©veloppeurs lors de la conception de pipelines de traitement des donnÃ©es en continu.

3. **IntÃ©gration avec Spark Core:**
   - Le module Spark Streaming est Ã©troitement intÃ©grÃ© avec Spark Core, ce qui signifie que les dÃ©veloppeurs peuvent combiner le traitement en temps rÃ©el avec le traitement par lots dans la mÃªme application Spark. Cela offre une approche unifiÃ©e pour traiter les donnÃ©es Ã  la fois en temps rÃ©el et par lots.

4. **Traitement de FenÃªtres:**
   - Spark Streaming prend en charge le traitement basÃ© sur des fenÃªtres temporelles, facilitant la crÃ©ation d'analyses basÃ©es sur des fenÃªtres glissantes ou des fenÃªtres fixes.

5. **API Conviviale:**
   - L'API Spark Streaming est conÃ§ue pour Ãªtre similaire Ã  l'API de traitement par lots de Spark, simplifiant ainsi la transition des dÃ©veloppeurs du traitement par lots au traitement en temps rÃ©el.

## ğŸ›ï¸Architecture

L'architecture de Spark Streaming est basÃ©e sur le concept de micro-batch. Les flux de donnÃ©es en continu sont divisÃ©s en petits lots, puis traitÃ©s par le moteur Spark Core. Ces lots peuvent Ãªtre traitÃ©s en parallÃ¨le, offrant une scalabilitÃ© horizontale.

## ğŸ“‹Cas d'Utilisation

1. **Analyse en Temps RÃ©el:**
   - Spark Streaming est souvent utilisÃ© pour l'analyse en temps rÃ©el des donnÃ©es provenant de sources telles que les rÃ©seaux sociaux, les capteurs IoT, etc. Cela permet aux entreprises de prendre des dÃ©cisions plus rapides en fonction des derniÃ¨res informations disponibles.

2. **Surveillance et Alerte:**
   - Les entreprises utilisent Spark Streaming pour surveiller en temps rÃ©el les mÃ©triques, les journaux, et dÃ©clencher des alertes immÃ©diates en cas de comportement anormal.

3. **Traitement de Flux d'Ã‰vÃ©nements:**
   - Les applications de traitement de flux d'Ã©vÃ©nements, comme le traitement des transactions financiÃ¨res en temps rÃ©el, bÃ©nÃ©ficient de Spark Streaming pour son traitement efficace des flux de donnÃ©es.
# ğŸ¥Hospital Incidents Streaming App

Ce programme Java utilise Apache Spark pour effectuer un traitement en continu sur un flux de donnÃ©es reprÃ©sentant des incidents hospitaliers.

```java
 SparkSession ss = SparkSession.builder().appName("Hospital incidents streaming app").master("local[*]").getOrCreate();
        StructType schema = new StructType(
                new StructField[]{
                        new StructField("id", DataTypes.LongType, false, Metadata.empty()),
                        new StructField("titre", DataTypes.StringType, false, Metadata.empty()),
                        new StructField("description", DataTypes.StringType, false, Metadata.empty()),
                        new StructField("service", DataTypes.StringType, false, Metadata.empty()),
                        new StructField("date", DataTypes.StringType, false, Metadata.empty()),
                }
        );
```
Dans cette section du code, nous effectuons l'initialisation de la session Spark (SparkSession) et dÃ©finissons le schÃ©ma des donnÃ©es qui seront traitÃ©es par le programme Spark. La session Spark est essentielle pour l'utilisation des fonctionnalitÃ©s de Spark, et nous lui attribuons un nom distinct, "Hospital incidents streaming app", pour une identification claire dans l'interface utilisateur de Spark. De plus, nous spÃ©cifions le mode maÃ®tre en local avec autant de threads que de cÅ“urs disponibles sur la machine.

En ce qui concerne le schÃ©ma des donnÃ©es, nous utilisons la classe StructType pour dÃ©crire la structure des informations que nous allons manipuler. Nous crÃ©ons des objets StructField pour chaque champ du schÃ©ma, en prÃ©cisant le nom du champ, son type de donnÃ©es, et si la valeur peut Ãªtre nulle. Dans cet exemple, le schÃ©ma comprend cinq champs : "id" de type Long, "titre" de type String, "description" de type String, "service" de type String, et "date" de type String. Cette Ã©tape prÃ©liminaire est cruciale pour assurer la cohÃ©rence des donnÃ©es traitÃ©es tout au long du processus de streaming.

```java
        Dataset<Row> incidents = ss
                .readStream()
                .option("header", "true")
                .schema(schema)
                .csv("src/main/resources");

```
Cette portion de code est responsable de la lecture en continu des donnÃ©es Ã  partir d'un flux CSV Ã  l'aide de Spark
## Afficher dâ€™une maniÃ¨re continue le nombre dâ€™incidents par service

```java
        // compter le nombre d'incidents par service
        Dataset<Row> incidentsCountByService = incidents.groupBy("service").count();
       StreamingQuery query = incidentsCountByService
                .writeStream()
                .outputMode("update")
                .format("console")
                .trigger(Trigger.ProcessingTime("5000 milliseconds"))
                .start();
```

## Afficher dâ€™une maniÃ¨re continue les deux annÃ©e ou il a y avait plus dâ€™incidents
```java
        // compter le nombre d'incidents par annÃ©e
        Dataset<Row> incidentsByYear = incidents
                .withColumn("year", year(col("date")))
                .groupBy("year")
                .agg(count("*").as("incidentCount"))
                .orderBy(desc("incidentCount"));
        StreamingQuery query1= incidentsByYear
                .writeStream()
                .outputMode("complete")
                .format("console")
                .trigger(Trigger.ProcessingTime("5000 milliseconds"))
                .start();
```

Ces lignes de code marquent la fin du traitement en continu du flux de donnÃ©es. En utilisant les mÃ©thodes awaitTermination(), le programme Spark attend que les deux requÃªtes (query et query1) se terminent avant de poursuivre ou de se terminer lui-mÃªme.
```java
       //la fin du streaming
        query.awaitTermination();
        query1.awaitTermination();
```
**Note:** Les rÃ©sultats sont continuellement mis Ã  jour en fonction de la configuration du dÃ©clencheur.

## ğŸ“ˆRÃ©sultats
Les rÃ©sultats varient entre les lots de traitement, avec des diffÃ©rences notables dans le nombre d'incidents par service et par annÃ©e. Ces variations peuvent Ãªtre dues Ã  l'arrivÃ©e de nouvelles donnÃ©es, des opÃ©rations de fenÃªtrage temporel, le parallÃ©lisme de traitement de Spark, et des nuances dans l'ordre de traitement des donnÃ©es. Une comprÃ©hension approfondie de la logique de l'application est essentielle pour interprÃ©ter ces divergences.
1. ***Batch 0***
   
![Nom de l'image](/streaming/batch00.PNG)

2. ***Batch 1***
   
![Nom de l'image](/streaming/batch11.PNG)

3. ***Batch 2***
   
![Nom de l'image](/streaming/batch2.PNG)


## ğŸConclusion

En un an, Spark Streaming a Ã©mergÃ© comme une technologie puissante pour le traitement des donnÃ©es en temps rÃ©el. Son intÃ©gration transparente avec Spark Core, sa flexibilitÃ© dans l'ingestion de donnÃ©es, et son modÃ¨le de programmation convivial en font un choix populaire parmi les dÃ©veloppeurs pour les applications de traitement en continu. Avec une communautÃ© active et un support continu, Spark Streaming reste une solution de pointe pour les besoins d'analyse en temps rÃ©el.
